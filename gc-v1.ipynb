{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install imutils","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:32.755869Z","iopub.execute_input":"2021-10-13T02:57:32.756562Z","iopub.status.idle":"2021-10-13T02:57:39.455964Z","shell.execute_reply.started":"2021-10-13T02:57:32.756524Z","shell.execute_reply":"2021-10-13T02:57:39.455149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **1. Data manipulation**","metadata":{}},{"cell_type":"markdown","source":"## **1.1 Import libaries**","metadata":{}},{"cell_type":"code","source":"\nimport time\nimport os\nimport cv2\nimport random\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torchvision import models\nfrom torch import optim\nfrom sklearn.metrics import *\nfrom PIL import Image\nimport shutil\nimport copy\nfrom collections import OrderedDict","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:39.460404Z","iopub.execute_input":"2021-10-13T02:57:39.460679Z","iopub.status.idle":"2021-10-13T02:57:39.471431Z","shell.execute_reply.started":"2021-10-13T02:57:39.460647Z","shell.execute_reply":"2021-10-13T02:57:39.470565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_workers = 4 #change this parameter based on your system configuration\nbatch_size = 32 #change this parameter based on your system configuration\nseed = 24\nrandom.seed(seed)\nmetrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\nclasses = ['covid', 'normal', 'pneumonia']\nnum_classes = len(classes)\nsplits = ['train', 'validation', 'testing']","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:39.472914Z","iopub.execute_input":"2021-10-13T02:57:39.473345Z","iopub.status.idle":"2021-10-13T02:57:39.481783Z","shell.execute_reply.started":"2021-10-13T02:57:39.473289Z","shell.execute_reply":"2021-10-13T02:57:39.480969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_FILES_PATH = \"../working\"\nDATA_PATH=\"../input/mycovid19gc/\"\nDATA_FILES_FULL_PATH = os.path.expanduser(DATA_FILES_PATH)\nSAVED_MODEL_FILE_NAME = os.path.join(DATA_FILES_FULL_PATH, \"keras_spell_e{}.h5\") # an HDF5 file\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:39.484267Z","iopub.execute_input":"2021-10-13T02:57:39.484575Z","iopub.status.idle":"2021-10-13T02:57:39.490791Z","shell.execute_reply.started":"2021-10-13T02:57:39.484496Z","shell.execute_reply":"2021-10-13T02:57:39.489806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **2. Statistics**","metadata":{}},{"cell_type":"code","source":"def showDatasetSize(data_path=DATA_PATH):\n    df = pd.DataFrame(columns = ['label'] + splits, index = classes)\n    for row in classes:\n        for col in splits:\n            df.loc[row,col] = int(len(os.listdir(os.path.join(data_path, col+'/'+row))))\n    df['total'] = df.sum(axis=1).astype(int)\n    df.loc['TOTAL'] = df.sum(axis=0).astype(int)\n    df['label'] = ['0', '1', '2','']\n    print(df)\n    return df\ndf_dataset = showDatasetSize()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:39.492454Z","iopub.execute_input":"2021-10-13T02:57:39.492802Z","iopub.status.idle":"2021-10-13T02:57:39.527973Z","shell.execute_reply.started":"2021-10-13T02:57:39.492767Z","shell.execute_reply":"2021-10-13T02:57:39.527261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **3. Load data**","metadata":{}},{"cell_type":"code","source":"def load_data(data_path=DATA_PATH, num_workers=num_workers):\n    transform_dict = {\n        'model': transforms.Compose(\n                                    [transforms.Resize(224),\n                                     transforms.CenterCrop(224),\n                                     transforms.ToTensor(),\n                                     ])}\n    train_data = datasets.ImageFolder(root=data_path + '/train', transform=transform_dict['model'])\n    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n    val_data = datasets.ImageFolder(root=data_path + '/validation', transform=transform_dict['model'])\n    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    test_data = datasets.ImageFolder(root=data_path + '/testing', transform=transform_dict['model'])\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    return train_data, train_loader, val_data, val_loader, test_data, test_loader\n\ntrain_data, train_loader, val_data, val_loader, test_data, test_loader = load_data()\ndataset = torch.utils.data.ConcatDataset([train_data, val_data, test_data])","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:39.529169Z","iopub.execute_input":"2021-10-13T02:57:39.529581Z","iopub.status.idle":"2021-10-13T02:57:39.655914Z","shell.execute_reply.started":"2021-10-13T02:57:39.529546Z","shell.execute_reply":"2021-10-13T02:57:39.655252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, train_loader, val_data, val_loader, test_data, test_loader = load_data()\ndataset = torch.utils.data.ConcatDataset([train_data, val_data, test_data])","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:39.657005Z","iopub.execute_input":"2021-10-13T02:57:39.657261Z","iopub.status.idle":"2021-10-13T02:57:39.779402Z","shell.execute_reply.started":"2021-10-13T02:57:39.65723Z","shell.execute_reply":"2021-10-13T02:57:39.778728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:39.781798Z","iopub.execute_input":"2021-10-13T02:57:39.782395Z","iopub.status.idle":"2021-10-13T02:57:39.789678Z","shell.execute_reply.started":"2021-10-13T02:57:39.78236Z","shell.execute_reply":"2021-10-13T02:57:39.788946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:39.79125Z","iopub.execute_input":"2021-10-13T02:57:39.791833Z","iopub.status.idle":"2021-10-13T02:57:39.802293Z","shell.execute_reply.started":"2021-10-13T02:57:39.791781Z","shell.execute_reply":"2021-10-13T02:57:39.801418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_batch_images(dataset):\n    n_images, scale = 8, 3\n    data_loader = torch.utils.data.DataLoader(dataset, batch_size=25*n_images, shuffle = True)\n    images, labels = next(iter(data_loader))\n    for i in range(len(classes)):\n        print(f'Class: {classes[i]}')\n        images_category = images[labels==i][:n_images]\n        grid = torchvision.utils.make_grid(images_category, padding=20)\n        npgrid = grid.cpu().numpy()\n        plt.figure(figsize=(40*scale/n_images, 20*scale/n_images))\n        plt.imshow(np.transpose(npgrid, (1, 2, 0)), interpolation='nearest')\n        plt.show()\n        plt.savefig('x-ray[i].pdf')  \n        #plt.savefig(\"viz1.png\", bbox_inches='tight')\n\nshow_batch_images(train_data)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:39.806773Z","iopub.execute_input":"2021-10-13T02:57:39.807476Z","iopub.status.idle":"2021-10-13T02:57:45.036524Z","shell.execute_reply.started":"2021-10-13T02:57:39.807439Z","shell.execute_reply":"2021-10-13T02:57:45.035841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'You are using {device}')","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.037825Z","iopub.execute_input":"2021-10-13T02:57:45.038253Z","iopub.status.idle":"2021-10-13T02:57:45.044386Z","shell.execute_reply.started":"2021-10-13T02:57:45.038215Z","shell.execute_reply":"2021-10-13T02:57:45.043229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Development: using pre-trained modules**","metadata":{}},{"cell_type":"code","source":"def calc_metrics(predictions, actuals, row):\n    df = pd.DataFrame(columns =metrics)\n    Y_pred = np.concatenate(predictions, axis=0)\n    Y_test = np.concatenate(actuals, axis=0)\n    df.loc[row, 'Accuracy'] = accuracy_score(Y_test, Y_pred)\n    df.loc[row, 'Precision'] = precision_score(Y_test, Y_pred, average=\"macro\")\n    df.loc[row, 'Recall'] = recall_score(Y_test, Y_pred, average=\"macro\")\n    df.loc[row, 'F1-score'] = f1_score(Y_test, Y_pred, average=\"macro\")\n    return df\n\ndef create_confusion_matrix(preds, y_test):\n    ylist, predlist = [], []\n    for pred in preds:\n        for item in pred:\n            predlist.append(int(item))\n    for y in y_test:\n        for item in y:\n            ylist.append(int(item))\n    data_dict = {'y_Actual':    ylist, 'y_Predicted': predlist}\n    df = pd.DataFrame(data_dict, columns=['y_Actual','y_Predicted'])\n    cm = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['ACTUAL'], colnames=['PREDICTED'])\n    return cm\n\ndef plot_train_val_losses(df):\n    df2 = pd.melt(df, id_vars=['epoch'], value_vars=['train_loss', 'validation_loss'], var_name='process', value_name='loss')\n    sns.lineplot(x = \"epoch\", y = \"loss\", data = df2, hue = \"process\",\n                style = \"process\", palette = \"hot\", dashes = False, \n                markers = [\"o\", \"<\"],  legend=\"brief\").set_title(\"Train and Validation Losses by Epoch\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.046037Z","iopub.execute_input":"2021-10-13T02:57:45.046318Z","iopub.status.idle":"2021-10-13T02:57:45.064206Z","shell.execute_reply.started":"2021-10-13T02:57:45.046286Z","shell.execute_reply":"2021-10-13T02:57:45.063386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **1.1 Define models**","metadata":{}},{"cell_type":"code","source":"def train_all_model(model):\n    t_start = time.time()\n    global best_val_model\n    global best_val_loss\n    best_val_loss = 1\n    global best_val_epoch\n    best_val_epoch = 0\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    df = pd.DataFrame(columns = ['model_name', 'epoch', 'train_loss','train_acc'])\n    print(f\"Training model {model_name} with {df_dataset.loc['TOTAL', 'train']} samples and max of {n_epochs} epochs, and validating with {df_dataset.loc['TOTAL', 'validation']} samples\\n\")\n    train_size= len(dataset_loader)\n    for epoch in range(1, n_epochs+1):\n        # Beginning of training step\n        t0 = time.time()\n        model.train()\n        train_loss, val_loss,train_acc,val_acc = 0.0, 0.0, 0.0, 0.0\n        for i, (data, target) in enumerate(dataset_loader):\n            target = target.to(device)\n            data = data.to(device)\n            optimizer.zero_grad()\n            outputs = model(data)\n            _, Y_pred_tag = torch.max(outputs, dim = 1)\n            Y_pred_tag = Y_pred_tag.detach().cpu().numpy()\n            Y_pred_tag = Y_pred_tag.reshape(len(Y_pred_tag), 1).astype('int8')\n            Y_test = target.detach().cpu().numpy()\n            Y_test = Y_test.reshape(len(Y_test), 1).astype('int8')\n            train_acc += accuracy_score(Y_test, Y_pred_tag)\n            loss = criterion(outputs, target)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.detach().cpu().numpy()\n        # Beginning of evaluation step\n        \n        print(f\"Epoch {epoch}:\\t train loss={train_loss/train_size:.5f} \\t train acc={train_acc/train_size:.5f} \\t time={(time.time() - t0):.2f}s\")\n        df.loc[len(df)] = [model_name, epoch, train_loss/train_size,train_acc/train_size]\n        epoch_acc=train_acc/train_size\n        if epoch_acc >= best_acc :\n            best_acc = epoch_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n        if use_scheduler: scheduler.step(val_loss/val_size)   # Optional to use scheduler for dynamic learning rate\n    #print(f\"Best model has val loss={best_val_loss:.5f} for {best_val_epoch} epochs\")\n    time_elapsed = time.time() - t_start\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, df","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.06592Z","iopub.execute_input":"2021-10-13T02:57:45.066287Z","iopub.status.idle":"2021-10-13T02:57:45.082689Z","shell.execute_reply.started":"2021-10-13T02:57:45.066252Z","shell.execute_reply":"2021-10-13T02:57:45.081999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_val_model(model):\n    t_start = time.time()\n    global best_val_model\n    global best_val_loss\n    best_val_loss = 1\n    global best_val_epoch\n    best_val_epoch = 0\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    df = pd.DataFrame(columns = ['model_name', 'epoch', 'train_loss','train_acc', 'validation_loss','validation_acc'])\n    print(f\"Training model {model_name} with {df_dataset.loc['TOTAL', 'train']} samples and max of {n_epochs} epochs, and validating with {df_dataset.loc['TOTAL', 'validation']} samples\\n\")\n    train_size, val_size = len(train_loader), len(val_loader)\n    for epoch in range(1, n_epochs+1):\n        # Beginning of training step\n        t0 = time.time()\n        model.train()\n        train_loss, val_loss,train_acc,val_acc = 0.0, 0.0, 0.0, 0.0\n        for i, (data, target) in enumerate(train_loader):\n            target = target.to(device)\n            data = data.to(device)\n            optimizer.zero_grad()\n            outputs = model(data)\n            _, Y_pred_tag = torch.max(outputs, dim = 1)\n            Y_pred_tag = Y_pred_tag.detach().cpu().numpy()\n            Y_pred_tag = Y_pred_tag.reshape(len(Y_pred_tag), 1).astype('int8')\n            Y_test = target.detach().cpu().numpy()\n            Y_test = Y_test.reshape(len(Y_test), 1).astype('int8')\n            train_acc += accuracy_score(Y_test, Y_pred_tag)\n            loss = criterion(outputs, target)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.detach().cpu().numpy()\n        # Beginning of evaluation step\n        model.eval()\n        for j, (data, target) in enumerate(val_loader):\n            target = target.to(device)\n            data = data.to(device)\n            outputs = model(data)\n            loss = criterion(outputs, target)\n            val_loss += loss.detach().cpu().numpy()\n            _, Y_pred_tag = torch.max(outputs, dim = 1)\n            Y_pred_tag = Y_pred_tag.detach().cpu().numpy()\n            Y_pred_tag = Y_pred_tag.reshape(len(Y_pred_tag), 1).astype('int8')\n            Y_test = target.detach().cpu().numpy()\n            Y_test = Y_test.reshape(len(Y_test), 1).astype('int8')\n            val_acc += accuracy_score(Y_test, Y_pred_tag)\n        print(f\"Epoch {epoch}:\\t train loss={train_loss/train_size:.5f} \\t train acc={train_acc/train_size:.5f}\\t val loss={val_loss/val_size:.5f} \\t val acc={val_acc/val_size:.5f} \\t time={(time.time() - t0):.2f}s\")\n        epoch_acc=val_acc/val_size\n        df.loc[len(df)] = [model_name, epoch, train_loss/train_size,train_acc/train_size, val_loss/val_size,val_acc/val_size]\n        if epoch_acc >= best_acc :\n            best_acc = epoch_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n        if use_scheduler: scheduler.step(val_loss/val_size)   # Optional to use scheduler for dynamic learning rate\n    #print(f\"Best model has val loss={best_val_loss:.5f} for {best_val_epoch} epochs\")\n    time_elapsed = time.time() - t_start\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, df","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.084329Z","iopub.execute_input":"2021-10-13T02:57:45.084608Z","iopub.status.idle":"2021-10-13T02:57:45.106631Z","shell.execute_reply.started":"2021-10-13T02:57:45.084565Z","shell.execute_reply":"2021-10-13T02:57:45.105805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_val_model_kfold(model, train_loader_kfold):\n    t_start = time.time()\n    df = pd.DataFrame(columns = ['model_name', 'epoch', 'train'])\n    print(f\"Training model {model_name} with {df_dataset.loc['TOTAL', 'train']} samples and max of {n_epochs} epochs\")\n    train_size = len(train_loader_kfold)\n    for epoch in range(1, n_epochs+1):\n        # Beginning of training step\n        t0 = time.time()\n        #model.train()\n        train_loss = 0.0\n        for i, (data, target) in enumerate(train_loader_kfold):\n            target = target.to(device)\n            data = data.to(device)\n            optimizer.zero_grad()\n            outputs = model(data)\n            loss = criterion(outputs, target)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.detach().cpu().numpy()\n        print(f\"Epoch {epoch}:\\t train loss={train_loss/train_size:.5f} \\t time={(time.time() - t0):.2f}s\")\n        df.loc[len(df)] = [model_name, epoch, train_loss/train_size]\n    print(f\"Total time training and evaluating: {(time.time()-t_start):.2f}s\")\n    return model, df\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.107999Z","iopub.execute_input":"2021-10-13T02:57:45.108604Z","iopub.status.idle":"2021-10-13T02:57:45.120096Z","shell.execute_reply.started":"2021-10-13T02:57:45.108555Z","shell.execute_reply":"2021-10-13T02:57:45.119359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef calc_pred_actuals(model, loader):\n    predictions, actuals = [], []\n    with torch.no_grad():\n        for data, target in loader:\n            data = data.to(device)\n            target = target.to(device)\n            Y_pred_orig = model(data)\n            _, Y_pred_tag = torch.max(Y_pred_orig, dim = 1)\n            Y_pred_tag = Y_pred_tag.detach().cpu().numpy()\n            Y_pred_tag = Y_pred_tag.reshape(len(Y_pred_tag), 1).astype('int8')\n            Y_test = target.detach().cpu().numpy()\n            Y_test = Y_test.reshape(len(Y_test), 1).astype('int8')\n            predictions.append(Y_pred_tag)\n            actuals.append(Y_test)\n    return predictions, actuals","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.121377Z","iopub.execute_input":"2021-10-13T02:57:45.12201Z","iopub.status.idle":"2021-10-13T02:57:45.133176Z","shell.execute_reply.started":"2021-10-13T02:57:45.121974Z","shell.execute_reply":"2021-10-13T02:57:45.132277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy_model(model, loader):\n    model.eval()\n    print(f\"Testing the model {model_name} with {df_dataset.loc['TOTAL', 'testing']} samples \\n\")   \n    predictions, actuals = calc_pred_actuals(model, loader)\n    conf_matrix = create_confusion_matrix(predictions, actuals)\n    df_test = calc_metrics(predictions, actuals, 'Test Results').astype(float)\n    print(df_test)\n    return df_test, conf_matrix\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.134384Z","iopub.execute_input":"2021-10-13T02:57:45.134996Z","iopub.status.idle":"2021-10-13T02:57:45.14259Z","shell.execute_reply.started":"2021-10-13T02:57:45.13496Z","shell.execute_reply":"2021-10-13T02:57:45.14179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_resnet34( num_classes, use_pretrained=True):\n    model_ft = models.resnet34(pretrained=use_pretrained)\n    for param in model_ft.parameters():\n        param.requires_grad = False\n    num_ftrs = model_ft.fc.in_features\n   # model_ft.fc = nn.Linear(num_ftrs, num_classes)\n    model_ft.fc = nn.Sequential(\n                      nn.Linear(num_ftrs, 224), \n                      nn.ReLU(), \n                      nn.Dropout(0.4),\n                      nn.Linear(224, num_classes),                   \n                      nn.LogSoftmax(dim=1))\n    model_ft.to(device)\n    return model_ft","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.143802Z","iopub.execute_input":"2021-10-13T02:57:45.144435Z","iopub.status.idle":"2021-10-13T02:57:45.154853Z","shell.execute_reply.started":"2021-10-13T02:57:45.144399Z","shell.execute_reply":"2021-10-13T02:57:45.154071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vgg16_v2(num_classes,use_pretrained=True):\n    model_ft = models.vgg16_bn(pretrained=use_pretrained)\n    layers_vgg16 = nn.Sequential(OrderedDict([\n          ('fc1', nn.Linear(25088, 512)),\n          ('activation1', nn.ReLU()),\n          ('dropout1', nn.Dropout(0.4)),\n          ('fc2', nn.Linear(512, 256)),\n          ('activation2', nn.ReLU()),\n          ('dropout2', nn.Dropout()),\n          ('fc3', nn.Linear(256, 128)),\n          ('activation3', nn.ReLU()),\n          ('dropout3', nn.Dropout()),\n           ('fc4', nn.Linear(128, 1)),\n           ('out', nn.Softmax())]))\n    num_ftrs = model_ft.classifier[6].in_features\n    #model_ft.fc = nn.Linear(num_ftrs, num_classes)\n    model_ft.classifier[6] = nn.Sequential(\n                      nn.Linear(num_ftrs, 224), \n                      nn.ReLU(), \n                      nn.Dropout(0.4),\n                      nn.Linear(224, num_classes),                   \n                      nn.LogSoftmax(dim=1))\n    model_ft.to(device)\n\n   # model_ft.classifier = layers_vgg16 #or _vgg19, or _resnet34\n    return model_ft","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.15616Z","iopub.execute_input":"2021-10-13T02:57:45.156911Z","iopub.status.idle":"2021-10-13T02:57:45.167433Z","shell.execute_reply.started":"2021-10-13T02:57:45.156858Z","shell.execute_reply":"2021-10-13T02:57:45.16668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vgg16(num_classes,use_pretrained=True):\n    model_ft = models.vgg16_bn(pretrained=use_pretrained)\n    for param in model_ft.parameters():\n        param.requires_grad = False\n    num_ftrs = model_ft.classifier[6].in_features\n    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n    model_ft.to(device)\n    return model_ft","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.168644Z","iopub.execute_input":"2021-10-13T02:57:45.169175Z","iopub.status.idle":"2021-10-13T02:57:45.179449Z","shell.execute_reply.started":"2021-10-13T02:57:45.169141Z","shell.execute_reply":"2021-10-13T02:57:45.178592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_vgg16( num_classes, use_pretrained=True):\n    model_ft = models.vgg19_bn(pretrained=use_pretrained)\n    for param in model_ft.parameters():\n        param.requires_grad = False\n    num_ftrs = model_ft.classifier[6].in_features\n    #model_ft.fc = nn.Linear(num_ftrs, num_classes)\n    model_ft.classifier[6] = nn.Sequential(\n                      nn.Linear(num_ftrs, 224), \n                      nn.ReLU(), \n                      nn.Dropout(0.4),\n                      nn.Linear(224, num_classes),                   \n                      nn.LogSoftmax(dim=1))\n    model_ft.to(device)\n    model_ft = nn.DataParallel(model_ft)\n    return model_ft","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.180772Z","iopub.execute_input":"2021-10-13T02:57:45.181607Z","iopub.status.idle":"2021-10-13T02:57:45.189569Z","shell.execute_reply.started":"2021-10-13T02:57:45.181571Z","shell.execute_reply":"2021-10-13T02:57:45.188834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_inception(  num_classes, use_pretrained=True):\n    model_ft = models.inception_v3(pretrained=use_pretrained)\n    for param in model_ft.parameters():\n        param.requires_grad = False\n            #param.aux_logits = False    \n        #num_ftrs = model_ft.fc.in_features\n        #model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n    num_ftrs = model_ft.fc.in_features\n    model_ft.fc = nn.Sequential(\n                      nn.Linear(num_ftrs, 224), \n                      nn.ReLU(), \n                      nn.Dropout(0.4),\n                      nn.Linear(224, num_classes),                   \n                      nn.LogSoftmax(dim=1))\n    model_ft.aux_logits = False\n    model_ft.to(device)\n    return model_ft","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.190861Z","iopub.execute_input":"2021-10-13T02:57:45.191521Z","iopub.status.idle":"2021-10-13T02:57:45.201367Z","shell.execute_reply.started":"2021-10-13T02:57:45.191483Z","shell.execute_reply":"2021-10-13T02:57:45.200567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **1.2 Pre-trained model example: resnet34**","metadata":{}},{"cell_type":"code","source":"model_name=\"vgg16\"\nvgg16_model=vgg16_v2(num_classes,use_pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:45.202666Z","iopub.execute_input":"2021-10-13T02:57:45.203337Z","iopub.status.idle":"2021-10-13T02:57:46.833695Z","shell.execute_reply.started":"2021-10-13T02:57:45.203302Z","shell.execute_reply":"2021-10-13T02:57:46.832954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(seed)\ntorch.manual_seed(seed)\nn_epochs = 20\nlearning_rate = 1e-2\ncriterion = nn.CrossEntropyLoss()\n#optimizer=torch.optim.Adam(vgg16_model.parameters(), lr=learning_rate,  weight_decay=learning_rate/n_epochs)\noptimizer = torch.optim.SGD(vgg16_model.parameters(), lr=learning_rate)\nuse_scheduler = False   # Set True if using scheduler\n","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:46.834912Z","iopub.execute_input":"2021-10-13T02:57:46.835319Z","iopub.status.idle":"2021-10-13T02:57:46.843264Z","shell.execute_reply.started":"2021-10-13T02:57:46.835283Z","shell.execute_reply":"2021-10-13T02:57:46.842525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model, df_vgg16_epochs = train_all_model(vgg16_model)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T21:45:42.899176Z","iopub.execute_input":"2021-10-10T21:45:42.899786Z","iopub.status.idle":"2021-10-10T23:08:17.52901Z","shell.execute_reply.started":"2021-10-10T21:45:42.899748Z","shell.execute_reply":"2021-10-10T23:08:17.527396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH=\"./\"\ntorch.save(pretrained_model.state_dict(), os.path.join(MODEL_PATH, 'finalourmodel.pth'))","metadata":{"execution":{"iopub.status.busy":"2021-10-10T23:08:47.551316Z","iopub.execute_input":"2021-10-10T23:08:47.552046Z","iopub.status.idle":"2021-10-10T23:08:49.939399Z","shell.execute_reply.started":"2021-10-10T23:08:47.552011Z","shell.execute_reply":"2021-10-10T23:08:49.93854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrain_model = vgg16_v2(num_classes,True)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T23:09:19.410102Z","iopub.execute_input":"2021-10-10T23:09:19.410398Z","iopub.status.idle":"2021-10-10T23:09:21.095221Z","shell.execute_reply.started":"2021-10-10T23:09:19.410332Z","shell.execute_reply":"2021-10-10T23:09:21.094476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_model.load_state_dict(torch.load('../input/modelg/finalourmodel.pth'))\nmy_submission = pd.DataFrame(columns=[\"case\",\"class\"])","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:52.663922Z","iopub.execute_input":"2021-10-13T02:57:52.664494Z","iopub.status.idle":"2021-10-13T02:57:53.116569Z","shell.execute_reply.started":"2021-10-13T02:57:52.664455Z","shell.execute_reply":"2021-10-13T02:57:53.115781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_test_data(data_path=\"../input/testfolder/\", num_workers=num_workers):\n    transform_dict = {\n        'model': transforms.Compose(\n                                    [transforms.Resize(224),\n                                     transforms.CenterCrop(224),\n                                     transforms.ToTensor(),\n                                     ])}\n    test_data = datasets.ImageFolder(root=data_path, transform=transform_dict['model'])\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    return  test_data, test_loader\n\ntest_data, test_loader = load_test_data()\ndataset_test = torch.utils.data.ConcatDataset([test_data])","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:54.044851Z","iopub.execute_input":"2021-10-13T02:57:54.045573Z","iopub.status.idle":"2021-10-13T02:57:54.06275Z","shell.execute_reply.started":"2021-10-13T02:57:54.045537Z","shell.execute_reply":"2021-10-13T02:57:54.062028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nwith torch.no_grad():\n    ind=0\n    pred=[]\n    for i,(data, target) in enumerate(test_loader, 0):\n        data = data.to(device)\n        Y_pred_orig = vgg16_model(data)\n        _, Y_pred_tag = torch.max(Y_pred_orig, dim = 1)\n        Y_pred_tag = Y_pred_tag.detach().cpu().numpy()\n        Y_pred_tag = Y_pred_tag.reshape(len(Y_pred_tag), 1).astype('int8')\n        for va in Y_pred_tag.tolist():\n            pred.append(va[0])\n            dic=dict()\n            number_str=str(len(my_submission)+1)\n            zero_filled_number = number_str.zfill(4)\n            name=str(zero_filled_number)+\".jpg\"\n            my_submission.loc[len(my_submission)]=[name,va[0]] ","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:57:55.088157Z","iopub.execute_input":"2021-10-13T02:57:55.08882Z","iopub.status.idle":"2021-10-13T02:58:10.103334Z","shell.execute_reply.started":"2021-10-13T02:57:55.088781Z","shell.execute_reply":"2021-10-13T02:58:10.102378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.remove(\"./submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:41:36.861431Z","iopub.execute_input":"2021-10-13T02:41:36.862141Z","iopub.status.idle":"2021-10-13T02:41:36.867472Z","shell.execute_reply.started":"2021-10-13T02:41:36.862105Z","shell.execute_reply":"2021-10-13T02:41:36.866598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_csv = pd.read_csv(\"../input/mycovid19gc/submission.csv\")\ntest_csv[' class'] = pred","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:58:10.108166Z","iopub.execute_input":"2021-10-13T02:58:10.108387Z","iopub.status.idle":"2021-10-13T02:58:10.121752Z","shell.execute_reply.started":"2021-10-13T02:58:10.108359Z","shell.execute_reply":"2021-10-13T02:58:10.120964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = input(\"Enter the name\")\ntest_csv.to_csv(str(name)+\".txt\", index = False,sep=\",\")","metadata":{"execution":{"iopub.status.busy":"2021-10-13T03:00:18.555281Z","iopub.execute_input":"2021-10-13T03:00:18.555538Z","iopub.status.idle":"2021-10-13T03:00:25.171463Z","shell.execute_reply.started":"2021-10-13T03:00:18.555512Z","shell.execute_reply":"2021-10-13T03:00:25.170647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_csv","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:35:32.522125Z","iopub.execute_input":"2021-10-13T02:35:32.522431Z","iopub.status.idle":"2021-10-13T02:35:32.53468Z","shell.execute_reply.started":"2021-10-13T02:35:32.522401Z","shell.execute_reply":"2021-10-13T02:35:32.533959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submission.to_csv('submission.txt',index=False, delimiter=\"\\t\")","metadata":{"execution":{"iopub.status.busy":"2021-10-13T02:59:55.393539Z","iopub.execute_input":"2021-10-13T02:59:55.393816Z","iopub.status.idle":"2021-10-13T02:59:55.422769Z","shell.execute_reply.started":"2021-10-13T02:59:55.393788Z","shell.execute_reply":"2021-10-13T02:59:55.421266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"./submission.txt\"> Download File </a>","metadata":{}},{"cell_type":"code","source":"my_submission","metadata":{"execution":{"iopub.status.busy":"2021-10-10T23:14:48.52527Z","iopub.execute_input":"2021-10-10T23:14:48.525857Z","iopub.status.idle":"2021-10-10T23:14:48.545103Z","shell.execute_reply.started":"2021-10-10T23:14:48.525803Z","shell.execute_reply":"2021-10-10T23:14:48.544325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_train_val_losses(df_vgg16_epochs)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:09:59.651342Z","iopub.execute_input":"2021-10-09T22:09:59.652283Z","iopub.status.idle":"2021-10-09T22:09:59.973392Z","shell.execute_reply.started":"2021-10-09T22:09:59.652236Z","shell.execute_reply":"2021-10-09T22:09:59.972476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vgg_results, conf_vgg_matrix_test = accuracy_model(pretrained_model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:10:17.743175Z","iopub.execute_input":"2021-10-09T22:10:17.74346Z","iopub.status.idle":"2021-10-09T22:10:38.073109Z","shell.execute_reply.started":"2021-10-09T22:10:17.743429Z","shell.execute_reply":"2021-10-09T22:10:38.072276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **RESNET34**","metadata":{}},{"cell_type":"code","source":"model_name=\"resnet34\"\nresnet34_model = generate_resnet34(  num_classes, use_pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:41:40.940703Z","iopub.execute_input":"2021-10-10T09:41:40.941428Z","iopub.status.idle":"2021-10-10T09:41:41.55118Z","shell.execute_reply.started":"2021-10-10T09:41:40.941389Z","shell.execute_reply":"2021-10-10T09:41:41.550445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(seed)\ntorch.manual_seed(seed)\nn_epochs = 20\nlearning_rate = 1e-2\ncriterion = nn.CrossEntropyLoss()\n#optimizer=torch.optim.Adam(vgg16_model.parameters(), lr=learning_rate,  weight_decay=learning_rate/n_epochs)\noptimizer = torch.optim.SGD(resnet34_model.parameters(), lr=learning_rate)\nuse_scheduler = False   # Set True if using scheduler","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:41:41.68299Z","iopub.execute_input":"2021-10-10T09:41:41.68367Z","iopub.status.idle":"2021-10-10T09:41:41.693428Z","shell.execute_reply.started":"2021-10-10T09:41:41.683618Z","shell.execute_reply":"2021-10-10T09:41:41.692473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npretrained_model_resnet34, df_resnet34_epochs = train_val_model(resnet34_model)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:41:42.313986Z","iopub.execute_input":"2021-10-10T09:41:42.316014Z","iopub.status.idle":"2021-10-10T10:46:57.274917Z","shell.execute_reply.started":"2021-10-10T09:41:42.315968Z","shell.execute_reply":"2021-10-10T10:46:57.274047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_train_val_losses(df_resnet34_epochs)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T10:46:57.277029Z","iopub.execute_input":"2021-10-10T10:46:57.277997Z","iopub.status.idle":"2021-10-10T10:46:57.56313Z","shell.execute_reply.started":"2021-10-10T10:46:57.277951Z","shell.execute_reply":"2021-10-10T10:46:57.562492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_resnet34_results, conf_resnet34_matrix_test = accuracy_model(pretrained_model_resnet34, test_loader)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T10:46:57.564276Z","iopub.execute_input":"2021-10-10T10:46:57.564514Z","iopub.status.idle":"2021-10-10T10:47:17.190082Z","shell.execute_reply.started":"2021-10-10T10:46:57.56448Z","shell.execute_reply":"2021-10-10T10:47:17.18842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Intercept**","metadata":{}},{"cell_type":"code","source":"model_name=\"inception\"\ninception_model = generate_inception(  num_classes, use_pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T10:47:17.19286Z","iopub.execute_input":"2021-10-10T10:47:17.193162Z","iopub.status.idle":"2021-10-10T10:47:19.634804Z","shell.execute_reply.started":"2021-10-10T10:47:17.193118Z","shell.execute_reply":"2021-10-10T10:47:19.634098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(seed)\ntorch.manual_seed(seed)\nn_epochs = 20\nlearning_rate = 1e-2\ncriterion = nn.CrossEntropyLoss()\n#optimizer=torch.optim.Adam(vgg16_model.parameters(), lr=learning_rate,  weight_decay=learning_rate/n_epochs)\noptimizer = torch.optim.SGD(inception_model.parameters(), lr=learning_rate)\nuse_scheduler = False   # Set True if using scheduler","metadata":{"execution":{"iopub.status.busy":"2021-10-10T10:47:19.635977Z","iopub.execute_input":"2021-10-10T10:47:19.63633Z","iopub.status.idle":"2021-10-10T10:47:19.647996Z","shell.execute_reply.started":"2021-10-10T10:47:19.636294Z","shell.execute_reply":"2021-10-10T10:47:19.647306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model_inception, df_inception_epochs = train_val_model(inception_model)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T10:47:19.649206Z","iopub.execute_input":"2021-10-10T10:47:19.649801Z","iopub.status.idle":"2021-10-10T11:54:13.330663Z","shell.execute_reply.started":"2021-10-10T10:47:19.649764Z","shell.execute_reply":"2021-10-10T11:54:13.329819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_train_val_losses(df_inception_epochs)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-10T11:54:13.332235Z","iopub.execute_input":"2021-10-10T11:54:13.332849Z","iopub.status.idle":"2021-10-10T11:54:13.603219Z","shell.execute_reply.started":"2021-10-10T11:54:13.332803Z","shell.execute_reply":"2021-10-10T11:54:13.60247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_inception_results, conf_inception_matrix_test = accuracy_model(pretrained_model_inception, test_loader)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T11:54:13.604444Z","iopub.execute_input":"2021-10-10T11:54:13.604711Z","iopub.status.idle":"2021-10-10T11:54:31.174016Z","shell.execute_reply.started":"2021-10-10T11:54:13.604675Z","shell.execute_reply":"2021-10-10T11:54:31.173198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-10-10T09:41:32.986193Z","iopub.status.idle":"2021-10-10T09:41:32.987007Z","shell.execute_reply.started":"2021-10-10T09:41:32.986766Z","shell.execute_reply":"2021-10-10T09:41:32.98679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **CNN**","metadata":{}},{"cell_type":"code","source":"\nlayer = [128, 128, 256, 256, 3]\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, layer[0], 3, padding=1)\n        self.bn1 = nn.BatchNorm2d(layer[0])\n        self.pool1 = nn.MaxPool2d(kernel_size=4, stride=4)\n        self.conv2 = nn.Conv2d(layer[0], layer[1], 3, padding=1)\n        self.bn2 = nn.BatchNorm2d(layer[1])\n        self.conv3 = nn.Conv2d(layer[1], layer[2], 3, padding=1)\n        self.bn3 = nn.BatchNorm2d(layer[2])\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.linear1 = nn.Linear(14 * 14 * layer[2], layer[3])\n        self.linear2 = nn.Linear(layer[3], layer[4])\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout()\n    def forward(self, x):\n        x = self.pool1(self.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(self.relu(self.bn2(self.conv2(x))))\n        x = self.pool2(self.relu(self.bn3(self.conv3(x))))\n        x = x.reshape(x.size(0), -1)\n        x = self.relu(self.linear1(x))\n        x = self.dropout(x)\n        x = self.linear2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:06:00.689516Z","iopub.execute_input":"2021-10-10T16:06:00.689813Z","iopub.status.idle":"2021-10-10T16:06:00.706229Z","shell.execute_reply.started":"2021-10-10T16:06:00.689785Z","shell.execute_reply":"2021-10-10T16:06:00.705044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(seed)\ntorch.manual_seed(seed)\nnet = Net().to(device)\nmodel_name = 'DLH_COVID'\nn_epochs = 20\nlearning_rate = 1e-3\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\nuse_scheduler = False   # Set True if using scheduler","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:06:01.809536Z","iopub.execute_input":"2021-10-10T16:06:01.809819Z","iopub.status.idle":"2021-10-10T16:06:08.241541Z","shell.execute_reply.started":"2021-10-10T16:06:01.809791Z","shell.execute_reply":"2021-10-10T16:06:08.240603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"our_model, df_epochs = train_val_model(net)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T13:42:27.164214Z","iopub.execute_input":"2021-10-10T13:42:27.164489Z","iopub.status.idle":"2021-10-10T14:50:26.650377Z","shell.execute_reply.started":"2021-10-10T13:42:27.164457Z","shell.execute_reply":"2021-10-10T14:50:26.649516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_train_val_losses(df_epochs)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T14:50:26.652604Z","iopub.execute_input":"2021-10-10T14:50:26.65304Z","iopub.status.idle":"2021-10-10T14:50:26.928523Z","shell.execute_reply.started":"2021-10-10T14:50:26.652997Z","shell.execute_reply":"2021-10-10T14:50:26.927853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_results, conf_matrix_test = accuracy_model(our_model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T14:50:26.929854Z","iopub.execute_input":"2021-10-10T14:50:26.930111Z","iopub.status.idle":"2021-10-10T14:50:46.308459Z","shell.execute_reply.started":"2021-10-10T14:50:26.930079Z","shell.execute_reply":"2021-10-10T14:50:46.307662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\ndef validate_model_kfold(model, model_name, k_folds):\n    #model.eval()\n    print(f\"Validating the model {model_name} with {df_dataset.loc['TOTAL', 'train']} samples and {k_folds}-folds \\n\")\n    df = pd.DataFrame(columns = metrics)\n    kfold = KFold(n_splits=k_folds, shuffle=True)\n    print(len(dataset))\n    for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n        train_kfold_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, sampler=train_subsampler)\n        test_kfold_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, sampler=test_subsampler)\n        #model.apply(reset_weights)\n        model, df_vgg_epochs = train_val_model_kfold(model, train_kfold_loader)\n        predictions, actuals = calc_pred_actuals(model, test_kfold_loader)\n        conf_matrix = create_confusion_matrix(predictions, actuals)\n        df_aux = calc_metrics(predictions, actuals, 'FOLD '+str(fold+1))\n        df = df.append(df_aux)      \n    df.loc['Average'] = df.mean(axis=0)\n    print(df.astype(float))\n    return df.astype(float), conf_matrix\n","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:06:14.165881Z","iopub.execute_input":"2021-10-10T16:06:14.166604Z","iopub.status.idle":"2021-10-10T16:06:14.193384Z","shell.execute_reply.started":"2021-10-10T16:06:14.166573Z","shell.execute_reply":"2021-10-10T16:06:14.192408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name=\"vgg16\"\nvgg16_model=vgg16_v2(num_classes,use_pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:06:16.742789Z","iopub.execute_input":"2021-10-10T16:06:16.743104Z","iopub.status.idle":"2021-10-10T16:06:27.966139Z","shell.execute_reply.started":"2021-10-10T16:06:16.743076Z","shell.execute_reply":"2021-10-10T16:06:27.96523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(seed)\ntorch.manual_seed(seed)\nn_epochs = 20\nlearning_rate = 1e-2\ncriterion = nn.CrossEntropyLoss()\n#optimizer=torch.optim.Adam(vgg16_model.parameters(), lr=learning_rate,  weight_decay=learning_rate/n_epochs)\noptimizer = torch.optim.SGD(vgg16_model.parameters(), lr=learning_rate)\nuse_scheduler = False   # Set True if using scheduler\n","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:06:27.96813Z","iopub.execute_input":"2021-10-10T16:06:27.968449Z","iopub.status.idle":"2021-10-10T16:06:27.979167Z","shell.execute_reply.started":"2021-10-10T16:06:27.968407Z","shell.execute_reply":"2021-10-10T16:06:27.977927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_our_model_results, conf_matrix_our_model_val = validate_model_kfold(vgg16_model, model_name = 'vgg16', k_folds = 5)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:06:27.981117Z","iopub.execute_input":"2021-10-10T16:06:27.981804Z","iopub.status.idle":"2021-10-10T18:48:21.382062Z","shell.execute_reply.started":"2021-10-10T16:06:27.981762Z","shell.execute_reply":"2021-10-10T18:48:21.379763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_test_data(data_path=\"../input/testfolder/\", num_workers=num_workers):\n    transform_dict = {\n        'model': transforms.Compose(\n                                    [transforms.Resize(224),\n                                     transforms.CenterCrop(224),\n                                     transforms.ToTensor(),\n                                     ])}\n    test_data = datasets.ImageFolder(root=data_path, transform=transform_dict['model'])\n    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n    return  test_data, test_loader\n\ntest_data, test_loader = load_test_data()\ndataset_test = torch.utils.data.ConcatDataset([test_data])","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:58:40.10707Z","iopub.execute_input":"2021-10-09T22:58:40.10735Z","iopub.status.idle":"2021-10-09T22:58:40.126672Z","shell.execute_reply.started":"2021-10-09T22:58:40.107321Z","shell.execute_reply":"2021-10-09T22:58:40.125926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_pred(model, loader):\n    predictions = []\n    with torch.no_grad():\n        for data, target in loader:\n            data = data.to(device)\n            Y_pred_orig = model(data)\n            _, Y_pred_tag = torch.max(Y_pred_orig, dim = 1)\n            Y_pred_tag = Y_pred_tag.detach().cpu().numpy()\n            Y_pred_tag = Y_pred_tag.reshape(len(Y_pred_tag), 1).astype('int8')\n           \n            predictions.append(Y_pred_tag)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:59:26.654588Z","iopub.execute_input":"2021-10-09T22:59:26.655466Z","iopub.status.idle":"2021-10-09T22:59:26.661258Z","shell.execute_reply.started":"2021-10-09T22:59:26.655421Z","shell.execute_reply":"2021-10-09T22:59:26.660569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### print(f\"Testing the model {model_name} with {dataset_test['TOTAL', 'test']} samples \\n\") \npredictions= calc_pred(pretrained_model, test_loader)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T23:02:56.840449Z","iopub.execute_input":"2021-10-09T23:02:56.841163Z","iopub.status.idle":"2021-10-09T23:03:09.376065Z","shell.execute_reply.started":"2021-10-09T23:02:56.841124Z","shell.execute_reply":"2021-10-09T23:03:09.375015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_submission = pd.DataFrame(columns=[\"case\",\"class\"])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = open(MODEL_PATH+\"submission.csv\", \"w\")\nwith torch.no_grad():\n    for i,(data, target,samples_fname) in enumerate(test_loader, 0):\n        data = data.to(device)\n        Y_pred_orig = pretrained_model(data)\n        _, Y_pred_tag = torch.max(Y_pred_orig, dim = 1)\n        Y_pred_tag = Y_pred_tag.detach().cpu().numpy()\n        Y_pred_tag = Y_pred_tag.reshape(len(Y_pred_tag), 1).astype('int8')\n        f.write(\"\\n\".join([\n            \", \".join(x)\n            for x in zip(map(str,Y_pred_tag.tolist()), samples_fname)\n        ]) + \"\\n\")\n\nf.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name=\"vgg16\"\nvgg16_model = generate_vgg16(  num_classes, use_pretrained=True)\npretrained_vgg16_model, df_vgg16_epochs = train_val_model(vgg16_model)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T22:56:58.356902Z","iopub.execute_input":"2021-10-09T22:56:58.357344Z","iopub.status.idle":"2021-10-09T22:57:06.738712Z","shell.execute_reply.started":"2021-10-09T22:56:58.357303Z","shell.execute_reply":"2021-10-09T22:57:06.73555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_train_val_losses(df_vgg16_epochs)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T19:27:58.991349Z","iopub.status.idle":"2021-10-09T19:27:58.991972Z","shell.execute_reply.started":"2021-10-09T19:27:58.991754Z","shell.execute_reply":"2021-10-09T19:27:58.991775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_vgg_results, conf_vgg_matrix_test = accuracy_model(pretrained_vgg16_model, test_loader)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:14:49.640427Z","iopub.execute_input":"2021-10-04T16:14:49.640724Z","iopub.status.idle":"2021-10-04T16:14:54.936272Z","shell.execute_reply.started":"2021-10-04T16:14:49.640695Z","shell.execute_reply":"2021-10-04T16:14:54.935101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import the necessary packages\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport os\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:14:58.628924Z","iopub.execute_input":"2021-10-04T16:14:58.629216Z","iopub.status.idle":"2021-10-04T16:14:58.655239Z","shell.execute_reply.started":"2021-10-04T16:14:58.629188Z","shell.execute_reply":"2021-10-04T16:14:58.654235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Configuration(object):\n    \"\"\"Dump stuff here\"\"\"\n\nCONFIG = Configuration()\n# parameters for the training:\nCONFIG.batch_size = 100 # As the model changes in size, play with the batch size to best fit the process in memory\nCONFIG.epochs = 30 # due to mini-epochs.\nCONFIG.steps_per_epoch = 1000 # This is a mini-epoch. Using News 2013 an epoch would need to be ~60K.\nCONFIG.validation_steps = 10\nCONFIG.number_of_iterations = 10\nCONFIG.INIT_LR = 1e-3\n# since we are using Jupyter Notebooks we can replace our argument\n# parsing code with *hard coded* arguments and values\nargs = {\n    \"dataset\": \"../input/covid19gc/train\",\n    \"validation\": \"../input/covid19gc/validation\",\n     \"testing\": \"../input/covid19gc/testing\",\n    \"plot\": \"plot.png\",\n    \"model\": \"covid19.model\"\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:14:59.49922Z","iopub.execute_input":"2021-10-04T16:14:59.499551Z","iopub.status.idle":"2021-10-04T16:14:59.507115Z","shell.execute_reply.started":"2021-10-04T16:14:59.499506Z","shell.execute_reply":"2021-10-04T16:14:59.50603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_model():\n        # load the VGG16 network, ensuring the head FC layer sets are left\n    # off\n    baseModel = VGG16(weights=\"imagenet\", include_top=False,\n        input_tensor=Input(shape=(224, 224, 3)))\n\n    # construct the head of the model that will be placed on top of the\n    # the base model\n    headModel = baseModel.output\n    headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n    headModel = Flatten(name=\"flatten\")(headModel)\n    headModel = Dense(64, activation=\"relu\")(headModel)\n    headModel = Dropout(0.5)(headModel)\n    headModel = Dense(3, activation=\"softmax\")(headModel)\n\n    # place the head FC model on top of the base model (this will become\n    # the actual model we will train)\n    model = Model(inputs=baseModel.input, outputs=headModel)\n\n    # loop over all layers in the base model and freeze them so they will\n    # *not* be updated during the first training process\n    for layer in baseModel.layers:\n        layer.trainable = False\n    # compile our model\n    print(\"[INFO] compiling model...\")\n    opt = Adam(lr=CONFIG.INIT_LR , decay=CONFIG.INIT_LR  / CONFIG.epochs )\n    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n        metrics=[\"accuracy\"])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:15:01.377224Z","iopub.execute_input":"2021-10-04T16:15:01.378064Z","iopub.status.idle":"2021-10-04T16:15:01.38795Z","shell.execute_reply.started":"2021-10-04T16:15:01.378027Z","shell.execute_reply":"2021-10-04T16:15:01.386882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# grab the list of images in our dataset directory, then initialize\n# the list of data (i.e., images) and class images\ndef loadIamge(path):\n    print(\"[INFO] loading images...\")\n    imagePaths = list(paths.list_images(path))\n    data = []\n    labels = []\n    cnx=0\n    max_image = 1000\n    # loop over the image paths\n    for imagePath in imagePaths:\n\n        # extract the class label from the filename\n        label = imagePath.split(os.path.sep)[-2]\n\n        # load the image, swap color channels, and resize it to be a fixed\n        # 224x224 pixels while ignoring aspect ratio\n        image = cv2.imread(imagePath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (224, 224))\n        # update the data and labels lists, respectively\n        data.append(image)\n        labels.append(label)\n        cnx+=1\n    return data,labels\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:15:02.115579Z","iopub.execute_input":"2021-10-04T16:15:02.116417Z","iopub.status.idle":"2021-10-04T16:15:02.12631Z","shell.execute_reply.started":"2021-10-04T16:15:02.116375Z","shell.execute_reply":"2021-10-04T16:15:02.125049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataTransformation(data,labels):\n    data_shuffled,labels_shuffled=shuffle(data, labels)\n    labels_shuffled_np=np.array(labels_shuffled)\n    \n    \n    vec = lb.fit_transform(labels_shuffled_np)\n    labels_cate=to_categorical(vec)\n    return data_shuffled,labels_cate","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:15:02.904481Z","iopub.execute_input":"2021-10-04T16:15:02.905246Z","iopub.status.idle":"2021-10-04T16:15:02.918328Z","shell.execute_reply.started":"2021-10-04T16:15:02.905177Z","shell.execute_reply":"2021-10-04T16:15:02.91692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator(data, labels):\n    \"\"\"Returns a tuple (inputs, targets)\n    All arrays should contain the same number of samples.\n    The generator is expected to loop over its data indefinitely.\n    An epoch finishes when  samples_per_epoch samples have been seen by the model.\n    \"\"\"\n    while True:\n        for i in range(0, len(labels), CONFIG.batch_size):\n            X, y = np.array(data[i:i+ CONFIG.batch_size]),labels[i:i+ CONFIG.batch_size]\n            yield X, y\n                    ","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:15:03.804351Z","iopub.execute_input":"2021-10-04T16:15:03.804986Z","iopub.status.idle":"2021-10-04T16:15:03.811501Z","shell.execute_reply.started":"2021-10-04T16:15:03.804952Z","shell.execute_reply":"2021-10-04T16:15:03.810437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lb = LabelEncoder()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:15:05.230071Z","iopub.execute_input":"2021-10-04T16:15:05.230741Z","iopub.status.idle":"2021-10-04T16:15:05.236498Z","shell.execute_reply.started":"2021-10-04T16:15:05.230709Z","shell.execute_reply":"2021-10-04T16:15:05.234944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata,labels=loadIamge(args[\"dataset\"])\ndata,labels=dataTransformation(data,labels)\ndata_val,labels_val=loadIamge(args[\"validation\"])\ndata_val,labels_val=dataTransformation(data_val,labels_val)\ndata_test,labels_test=loadIamge(args[\"testing\"])\ndata_test,labels_test=dataTransformation(data_test,labels_test)\n#(valX, testX, valY, testY) = train_test_split(data_val, labels_val,test_size=0.20, stratify=labels_val, random_state=42)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-04T16:15:06.064032Z","iopub.execute_input":"2021-10-04T16:15:06.064325Z","iopub.status.idle":"2021-10-04T16:15:06.38717Z","shell.execute_reply.started":"2021-10-04T16:15:06.064297Z","shell.execute_reply":"2021-10-04T16:15:06.385909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OnEpochEndCallback(Callback):\n    \"\"\"Execute this every end of epoch\"\"\"\n\n    def on_epoch_end(self, epoch, logs=None):\n        \"\"\"On Epoch end - do some stats\"\"\"\n        X_val, y_val = next(generator(valX,valY))\n        print_random_predictions(self.model,  X_val, y_val)\n        self.model.save(SAVED_MODEL_FILE_NAME.format(epoch))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T22:04:16.496496Z","iopub.execute_input":"2021-09-21T22:04:16.496766Z","iopub.status.idle":"2021-09-21T22:04:16.505869Z","shell.execute_reply.started":"2021-09-21T22:04:16.496734Z","shell.execute_reply":"2021-09-21T22:04:16.50496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef print_random_predictions(model, X_val, y_val):\n    \"\"\"Select 10 samples from the validation set at random so we can visualize errors\"\"\"\n    print()\n    \n        # make predictions on the testing set\n    print(\"[INFO] evaluating network...\")\n    #predIdxs = model.predict(X_val, batch_size=CONFIG.batch_size)\n\n    # for each image in the testing set we need to find the index of the\n    # label with corresponding largest predicted probability\n    #predIdxs = np.argmax(predIdxs, axis=1)\n    \n    scores = model.evaluate(X_val, y_val, verbose=0)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n\n    # show a nicely formatted classification report\n   # print(classification_report(y_val.argmax(axis=1), predIdxs,target_names=lb.classes_))\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T22:04:16.50746Z","iopub.execute_input":"2021-09-21T22:04:16.507811Z","iopub.status.idle":"2021-09-21T22:04:16.522157Z","shell.execute_reply.started":"2021-09-21T22:04:16.507773Z","shell.execute_reply":"2021-09-21T22:04:16.52127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ON_EPOCH_END_CALLBACK = OnEpochEndCallback()","metadata":{"execution":{"iopub.status.busy":"2021-09-21T22:04:16.523807Z","iopub.execute_input":"2021-09-21T22:04:16.524219Z","iopub.status.idle":"2021-09-21T22:04:16.532354Z","shell.execute_reply.started":"2021-09-21T22:04:16.524181Z","shell.execute_reply":"2021-09-21T22:04:16.531453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def itarative_train(model,data,labels,data_val,labels_val):\n    \"\"\"\n    Iterative training of the model\n     - To allow for finite RAM...\n     - To allow infinite training data as the training noise is injected in runtime\n    \"\"\"\n    model.fit_generator(generator(data,labels), steps_per_epoch=CONFIG.steps_per_epoch,\n                        epochs=CONFIG.epochs,\n                        verbose=1, callbacks=[ON_EPOCH_END_CALLBACK, ], validation_data=generator(data_val,labels_val),\n                        validation_steps=CONFIG.validation_steps,\n                        class_weight=None, max_queue_size=10, workers=1,\n                        initial_epoch=0)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T22:04:16.535061Z","iopub.execute_input":"2021-09-21T22:04:16.535327Z","iopub.status.idle":"2021-09-21T22:04:16.543016Z","shell.execute_reply.started":"2021-09-21T22:04:16.535301Z","shell.execute_reply":"2021-09-21T22:04:16.541953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=generate_model()\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T22:04:16.544588Z","iopub.execute_input":"2021-09-21T22:04:16.545216Z","iopub.status.idle":"2021-09-21T22:04:19.35109Z","shell.execute_reply.started":"2021-09-21T22:04:16.545162Z","shell.execute_reply":"2021-09-21T22:04:19.350409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"itarative_train(model,data,labels,valX,valY)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T22:04:19.352309Z","iopub.execute_input":"2021-09-21T22:04:19.352554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}